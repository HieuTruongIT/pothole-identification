{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRdDYkqAKN4"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "d9a412cb-2772-43b1-c9a7-611c8be603ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "8720aaf5-915b-4e06-cb5a-6d08af77e312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trong\\Desktop\\NoctisAI - Detection\\server\\pothole-detection-camera\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **18.01.2023** with version **YOLOv8.0.9**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "b6eb60f3-49e5-4c11-ed66-c082aa2fcce6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.12.2 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "Setup complete  (8 CPUs, 7.7 GB RAM, 339.1/458.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.196\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VOEYrlBoP9-E"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnnZSm5OQfPQ"
   },
   "source": [
    "## CLI Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5RGYA6sPgEd"
   },
   "source": [
    "## Inference with Pre-trained COCO Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1qD4toTTw0"
   },
   "source": [
    "### üíª CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaE1kLS8R4CV"
   },
   "source": [
    "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDbMt_M6PiXb",
    "outputId": "2838bb7f-c3cf-417e-8bc7-7d1f615b3763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trong\\Desktop\\NoctisAI - Detection\\server\\pothole-detection-camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trong\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt to 'yolov8s-seg.pt'...\n",
      "\n",
      "  0%|          | 0.00/22.8M [00:00<?, ?B/s]\n",
      "  1%|          | 128k/22.8M [00:00<00:37, 642kB/s]\n",
      "  1%|          | 256k/22.8M [00:00<00:34, 682kB/s]\n",
      "  2%|‚ñè         | 384k/22.8M [00:00<00:39, 600kB/s]\n",
      "  2%|‚ñè         | 512k/22.8M [00:00<00:40, 578kB/s]\n",
      "  3%|‚ñé         | 640k/22.8M [00:01<00:35, 650kB/s]\n",
      "  3%|‚ñé         | 768k/22.8M [00:01<00:36, 629kB/s]\n",
      "  4%|‚ñç         | 896k/22.8M [00:01<00:31, 732kB/s]\n",
      "  4%|‚ñç         | 1.00M/22.8M [00:01<00:29, 772kB/s]\n",
      "  5%|‚ñç         | 1.12M/22.8M [00:01<00:31, 731kB/s]\n",
      "  5%|‚ñå         | 1.25M/22.8M [00:01<00:26, 840kB/s]\n",
      "  7%|‚ñã         | 1.50M/22.8M [00:02<00:21, 1.02MB/s]\n",
      "  7%|‚ñã         | 1.62M/22.8M [00:02<00:21, 1.04MB/s]\n",
      "  8%|‚ñä         | 1.88M/22.8M [00:02<00:21, 1.03MB/s]\n",
      "  9%|‚ñâ         | 2.00M/22.8M [00:02<00:20, 1.07MB/s]\n",
      " 10%|‚ñâ         | 2.25M/22.8M [00:02<00:15, 1.35MB/s]\n",
      " 11%|‚ñà         | 2.50M/22.8M [00:02<00:18, 1.17MB/s]\n",
      " 12%|‚ñà‚ñè        | 2.75M/22.8M [00:03<00:15, 1.37MB/s]\n",
      " 13%|‚ñà‚ñé        | 3.00M/22.8M [00:03<00:13, 1.49MB/s]\n",
      " 14%|‚ñà‚ñç        | 3.25M/22.8M [00:03<00:13, 1.54MB/s]\n",
      " 16%|‚ñà‚ñå        | 3.62M/22.8M [00:03<00:12, 1.65MB/s]\n",
      " 17%|‚ñà‚ñã        | 3.88M/22.8M [00:03<00:11, 1.76MB/s]\n",
      " 18%|‚ñà‚ñä        | 4.12M/22.8M [00:03<00:10, 1.89MB/s]\n",
      " 19%|‚ñà‚ñâ        | 4.38M/22.8M [00:03<00:10, 1.84MB/s]\n",
      " 20%|‚ñà‚ñà        | 4.62M/22.8M [00:04<00:11, 1.64MB/s]\n",
      " 21%|‚ñà‚ñà‚ñè       | 4.88M/22.8M [00:04<00:13, 1.42MB/s]\n",
      " 22%|‚ñà‚ñà‚ñè       | 5.12M/22.8M [00:04<00:12, 1.45MB/s]\n",
      " 24%|‚ñà‚ñà‚ñé       | 5.38M/22.8M [00:04<00:11, 1.52MB/s]\n",
      " 25%|‚ñà‚ñà‚ñå       | 5.75M/22.8M [00:04<00:09, 1.83MB/s]\n",
      " 26%|‚ñà‚ñà‚ñã       | 6.00M/22.8M [00:05<00:10, 1.63MB/s]\n",
      " 28%|‚ñà‚ñà‚ñä       | 6.38M/22.8M [00:05<00:08, 2.02MB/s]\n",
      " 29%|‚ñà‚ñà‚ñâ       | 6.62M/22.8M [00:05<00:08, 2.03MB/s]\n",
      " 30%|‚ñà‚ñà‚ñà       | 6.88M/22.8M [00:05<00:08, 1.93MB/s]\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 7.12M/22.8M [00:05<00:08, 2.04MB/s]\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 7.38M/22.8M [00:05<00:08, 1.95MB/s]\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 7.62M/22.8M [00:05<00:09, 1.60MB/s]\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 7.88M/22.8M [00:06<00:11, 1.38MB/s]\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 8.25M/22.8M [00:06<00:08, 1.80MB/s]\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 8.50M/22.8M [00:06<00:10, 1.48MB/s]\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 8.75M/22.8M [00:06<00:11, 1.32MB/s]\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 9.00M/22.8M [00:07<00:15, 918kB/s] \n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9.62M/22.8M [00:07<00:09, 1.49MB/s]\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 9.88M/22.8M [00:07<00:09, 1.39MB/s]\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10.1M/22.8M [00:08<00:14, 948kB/s] \n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10.4M/22.8M [00:08<00:12, 1.02MB/s]\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 10.8M/22.8M [00:08<00:09, 1.26MB/s]\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11.0M/22.8M [00:08<00:09, 1.27MB/s]\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11.2M/22.8M [00:09<00:11, 1.04MB/s]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11.4M/22.8M [00:09<00:11, 1.02MB/s]\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 11.6M/22.8M [00:09<00:11, 1.05MB/s]\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12.0M/22.8M [00:09<00:08, 1.34MB/s]\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12.2M/22.8M [00:10<00:08, 1.30MB/s]\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12.5M/22.8M [00:10<00:08, 1.26MB/s]\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 12.8M/22.8M [00:10<00:09, 1.15MB/s]\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 12.9M/22.8M [00:10<00:08, 1.17MB/s]\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13.0M/22.8M [00:10<00:09, 1.09MB/s]\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13.1M/22.8M [00:10<00:09, 1.01MB/s]\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13.2M/22.8M [00:11<00:09, 1.06MB/s]\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13.4M/22.8M [00:11<00:09, 1.07MB/s]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 13.6M/22.8M [00:11<00:06, 1.43MB/s]\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 13.9M/22.8M [00:11<00:06, 1.53MB/s]\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14.1M/22.8M [00:11<00:06, 1.36MB/s]\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 14.4M/22.8M [00:11<00:05, 1.53MB/s]\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 14.6M/22.8M [00:11<00:05, 1.58MB/s]\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 14.9M/22.8M [00:12<00:05, 1.57MB/s]\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15.1M/22.8M [00:12<00:05, 1.37MB/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15.4M/22.8M [00:12<00:05, 1.51MB/s]\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 15.6M/22.8M [00:12<00:05, 1.43MB/s]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16.0M/22.8M [00:12<00:03, 1.80MB/s]\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 16.4M/22.8M [00:12<00:03, 2.24MB/s]\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 16.6M/22.8M [00:13<00:03, 2.07MB/s]\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17.0M/22.8M [00:13<00:02, 2.42MB/s]\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 17.4M/22.8M [00:13<00:02, 2.04MB/s]\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 17.6M/22.8M [00:13<00:02, 1.90MB/s]\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 17.9M/22.8M [00:13<00:02, 2.03MB/s]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18.1M/22.8M [00:13<00:02, 1.67MB/s]\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 18.4M/22.8M [00:14<00:03, 1.42MB/s]\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 18.8M/22.8M [00:14<00:02, 1.83MB/s]\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19.0M/22.8M [00:14<00:02, 1.48MB/s]\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 19.4M/22.8M [00:14<00:02, 1.76MB/s]\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 19.6M/22.8M [00:15<00:02, 1.34MB/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 19.9M/22.8M [00:15<00:03, 805kB/s] \n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 20.5M/22.8M [00:16<00:02, 1.11MB/s]\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 20.8M/22.8M [00:16<00:01, 1.22MB/s]\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21.0M/22.8M [00:16<00:01, 1.15MB/s]\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 21.2M/22.8M [00:16<00:01, 1.01MB/s]\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 21.4M/22.8M [00:16<00:01, 1.05MB/s]\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 21.5M/22.8M [00:17<00:01, 860kB/s] \n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 21.8M/22.8M [00:17<00:01, 934kB/s]\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 21.9M/22.8M [00:17<00:01, 892kB/s]\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 22.0M/22.8M [00:17<00:00, 841kB/s]\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 22.1M/22.8M [00:17<00:00, 821kB/s]\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 22.2M/22.8M [00:18<00:00, 613kB/s]\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 22.6M/22.8M [00:18<00:00, 1.04MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.8M/22.8M [00:18<00:00, 940kB/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.8M/22.8M [00:18<00:00, 1.28MB/s]\n",
      "C:\\Users\\trong\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.196  Python-3.12.2 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i5-11320H 3.20GHz)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "Downloading https://media.roboflow.com/notebooks/examples/dog.jpeg to 'dog.jpeg'...\n",
      "\n",
      "  0%|          | 0.00/104k [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104k/104k [00:00<00:00, 485kB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104k/104k [00:00<00:00, 483kB/s]\n",
      "image 1/1 c:\\Users\\trong\\Desktop\\NoctisAI - Detection\\server\\pothole-detection-camera\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 1 handbag, 441.9ms\n",
      "Speed: 10.2ms preprocess, 441.9ms inference, 35.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mc:\\Users\\trong\\runs\\segment\\predict\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!yolo task=segment mode=predict model=yolov8s-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "LyopYpK1TQrB",
    "outputId": "c0c00af0-d908-4f84-dc1f-39fcf693c4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trong\\Desktop\\NoctisAI - Detection\\server\\pothole-detection-camera\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/segment/predict/dog.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{HOME}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns/segment/predict/dog.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/segment/predict/dog.jpeg'"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "Image(filename='runs/segment/predict/dog.jpeg', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFMBYQtMVL-B"
   },
   "source": [
    "### üêç Python SDK\n",
    "\n",
    "The simplest way of simply using YOLOv8 directly in a Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSd93ZJzZZKt",
    "outputId": "a0126b30-adb8-4790-af14-a51d2f311bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datasets\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.8/46.8 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.5/138.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentry-sdk 1.14.0 requires urllib3>=1.26.11; python_version >= \"3.6\", but you have urllib3 1.26.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in rpi4-yolov8-segmentation-1 to yolov8: 100% [1658619 / 1658619] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to rpi4-yolov8-segmentation-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:00<00:00, 2465.36it/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"928MyAxIm2K0hh8xRQ6C\")\n",
    "project = rf.workspace(\"freedomtech\").project(\"rpi4-yolov8-segmentation\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "7050c8d2-c781-4ded-8c99-f13eb28df9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt to yolov8s-seg.pt...\n",
      "100% 22.8M/22.8M [00:00<00:00, 34.3MB/s]\n",
      "\n",
      "Ultralytics YOLOv8.0.19 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=/content/datasets/rpi4-yolov8-segmentation-1/data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/segment/train2\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2771318  ultralytics.nn.modules.Segment               [2, 32, 128, [128, 256, 512]] \n",
      "YOLOv8s-seg summary: 261 layers, 11790870 parameters, 11790854 gradients, 42.7 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/rpi4-yolov8-segmentation-1/train/labels.cache... 27 images, 0 backgrounds, 0 corrupt: 100% 27/27 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/rpi4-yolov8-segmentation-1/valid/labels.cache... 7 images, 0 backgrounds, 0 corrupt: 100% 7/7 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      4.56G      1.324      2.737      4.802      1.458         15        640: 100% 2/2 [00:04<00:00,  2.08s/it]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          7          7      0.924      0.333      0.935      0.833      0.924      0.333      0.949      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      4.57G      1.235        2.4      4.107      1.358         19        640: 100% 2/2 [00:02<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all          7          7      0.901      0.333      0.944      0.831      0.901      0.333      0.944      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      4.57G      1.124      2.414      4.016      1.269         23        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.71it/s]\n",
      "                   all          7          7      0.859      0.333       0.94      0.822      0.859      0.333       0.94       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      4.57G      1.044      2.446      3.908      1.179         22        640: 100% 2/2 [00:02<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
      "                   all          7          7      0.924      0.417      0.984      0.854      0.924      0.417      0.984      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      4.59G      1.148      2.577      3.712      1.364         17        640: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
      "                   all          7          7      0.539          1      0.984      0.894      0.539          1      0.984      0.871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      4.59G      0.992       1.48      2.929      1.254         15        640: 100% 2/2 [00:02<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.64it/s]\n",
      "                   all          7          7      0.976      0.906      0.984       0.91      0.976      0.906      0.984      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      4.59G     0.8767       1.49      2.013      1.168         28        640: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.64it/s]\n",
      "                   all          7          7      0.967      0.976      0.995      0.928      0.967      0.976      0.995      0.868\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      4.59G     0.7249      1.407      1.733      1.119         21        640: 100% 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.70it/s]\n",
      "                   all          7          7      0.928          1      0.995      0.972      0.928          1      0.995      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      4.59G     0.7881      1.204      1.398      1.064         20        640: 100% 2/2 [00:02<00:00,  1.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
      "                   all          7          7      0.859      0.917      0.984       0.93      0.859      0.917      0.984      0.869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      4.59G      0.738      1.411      1.363      1.088         31        640: 100% 2/2 [00:02<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.59it/s]\n",
      "                   all          7          7      0.844      0.921      0.995      0.981      0.844      0.921      0.995      0.882\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      4.59G     0.7752      1.196      1.455      1.148         19        640: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.69it/s]\n",
      "                   all          7          7      0.943      0.849      0.995       0.97      0.943      0.849      0.995      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      4.59G     0.6897      1.326      1.083      1.054         25        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
      "                   all          7          7      0.969          1      0.995       0.92      0.969          1      0.995      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      4.59G     0.5809      1.149     0.9317     0.9881         19        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.62it/s]\n",
      "                   all          7          7      0.874          1      0.995      0.913      0.874          1      0.995      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      4.59G     0.6067     0.9092      1.279      1.002         17        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.60it/s]\n",
      "                   all          7          7       0.94          1      0.995      0.912       0.94          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      4.59G     0.5369      1.176     0.9886     0.9624         21        640: 100% 2/2 [00:02<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.67it/s]\n",
      "                   all          7          7      0.945          1      0.995      0.914      0.945          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      4.59G     0.6772       1.13     0.8829      1.029         20        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.73it/s]\n",
      "                   all          7          7      0.974          1      0.995      0.862      0.974          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      4.59G     0.7028      1.104     0.8523      1.026         22        640: 100% 2/2 [00:02<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.67it/s]\n",
      "                   all          7          7      0.947      0.964      0.995      0.902      0.947      0.964      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      4.59G     0.5471     0.9691     0.6876      0.971         19        640: 100% 2/2 [00:02<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.70it/s]\n",
      "                   all          7          7       0.91          1      0.995      0.902       0.91          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      4.59G     0.5651     0.9588     0.7202     0.9583         19        640: 100% 2/2 [00:02<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.68it/s]\n",
      "                   all          7          7      0.945          1      0.995      0.894      0.945          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      4.59G     0.6204      1.027     0.8978     0.9728         18        640: 100% 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.71it/s]\n",
      "                   all          7          7      0.958          1      0.995      0.907      0.958          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      4.59G     0.5822      1.032     0.7777     0.9404         13        640: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.71it/s]\n",
      "                   all          7          7      0.961          1      0.995      0.906      0.961          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      4.59G     0.5725     0.8755     0.5543     0.9575         27        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.78it/s]\n",
      "                   all          7          7      0.977          1      0.995      0.898      0.977          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      4.59G     0.6465     0.9815     0.6778     0.9319         20        640: 100% 2/2 [00:02<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.63it/s]\n",
      "                   all          7          7      0.941      0.928      0.995      0.888      0.941      0.928      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      4.59G       0.66      1.128     0.5959     0.9518         30        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.72it/s]\n",
      "                   all          7          7      0.971      0.927      0.995      0.888      0.971      0.927      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      4.59G     0.5877     0.9392     0.5419     0.9485         27        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.56it/s]\n",
      "                   all          7          7      0.824      0.989      0.995      0.895      0.824      0.989      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      4.59G     0.5696     0.7875     0.8275     0.9562         15        640: 100% 2/2 [00:02<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.77it/s]\n",
      "                   all          7          7      0.982          1      0.995      0.886      0.982          1      0.995      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      4.59G     0.6578     0.9513     0.7285     0.9592         26        640: 100% 2/2 [00:02<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.34it/s]\n",
      "                   all          7          7      0.983          1      0.995      0.888      0.983          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      4.59G     0.6327      0.889     0.9319     0.9542         16        640: 100% 2/2 [00:03<00:00,  1.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all          7          7      0.983          1      0.995      0.888      0.983          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      4.59G     0.6399     0.9091     0.7028     0.9745         23        640: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.72it/s]\n",
      "                   all          7          7      0.961      0.993      0.995      0.894      0.961      0.993      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      4.59G     0.6632     0.9422     0.7279     0.9382         20        640: 100% 2/2 [00:02<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.66it/s]\n",
      "                   all          7          7      0.976          1      0.995      0.894      0.976          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      4.59G     0.7017     0.9725     0.7021     0.9712         23        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.77it/s]\n",
      "                   all          7          7      0.976          1      0.995      0.894      0.976          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      4.59G     0.6594     0.9756     0.6691     0.9685         19        640: 100% 2/2 [00:02<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.82it/s]\n",
      "                   all          7          7      0.966          1      0.995      0.889      0.966          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      4.59G     0.5954     0.7765     0.4936     0.9712         21        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.967          1      0.995       0.89      0.967          1      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      4.59G     0.5522     0.7644     0.5629     0.9251         26        640: 100% 2/2 [00:02<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.967          1      0.995       0.89      0.967          1      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      4.59G     0.5768     0.8187       0.57     0.9115         26        640: 100% 2/2 [00:02<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.906       0.93      0.995      0.917      0.906       0.93      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      4.59G     0.6554     0.9316     0.6532     0.9206         17        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.74it/s]\n",
      "                   all          7          7      0.947      0.962      0.995      0.952      0.947      0.962      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      4.59G     0.7365     0.8692     0.5359     0.9987         15        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.79it/s]\n",
      "                   all          7          7      0.947      0.962      0.995      0.952      0.947      0.962      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      4.59G     0.6374     0.7932     0.5193     0.9475         22        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.80it/s]\n",
      "                   all          7          7      0.974          1      0.995      0.884      0.974          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      4.59G     0.6589     0.7897      0.545     0.9045         28        640: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.85it/s]\n",
      "                   all          7          7       0.76          1      0.995      0.881       0.76          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      4.59G     0.7508     0.8698     0.8557     0.9618         21        640: 100% 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.70it/s]\n",
      "                   all          7          7       0.76          1      0.995      0.881       0.76          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      4.59G     0.6623     0.9866     0.7566     0.9415         21        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.76it/s]\n",
      "                   all          7          7      0.979          1      0.995       0.87      0.979          1      0.995      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      4.59G     0.5682     0.9323     0.4757     0.9009         26        640: 100% 2/2 [00:02<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.917          1      0.995      0.893      0.917          1      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      4.59G     0.6197     0.7521     0.4878     0.9455         18        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.76it/s]\n",
      "                   all          7          7      0.917          1      0.995      0.893      0.917          1      0.995      0.889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      4.59G     0.5966     0.9425     0.6124     0.9423         20        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.91it/s]\n",
      "                   all          7          7      0.979          1      0.995      0.848      0.979          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      4.59G     0.5749     0.7293     0.4057     0.8858         24        640: 100% 2/2 [00:02<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.82it/s]\n",
      "                   all          7          7      0.979          1      0.995      0.848      0.979          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      4.59G     0.7048     0.8468     0.5419     0.9968         22        640: 100% 2/2 [00:02<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.80it/s]\n",
      "                   all          7          7       0.96          1      0.995      0.855       0.96          1      0.995      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      4.59G     0.6806     0.8431     0.5099     0.9554         19        640: 100% 2/2 [00:02<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.79it/s]\n",
      "                   all          7          7       0.96          1      0.995      0.855       0.96          1      0.995      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      4.59G     0.6089     0.8562     0.5133     0.9157         21        640: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.77it/s]\n",
      "                   all          7          7       0.98          1      0.995        0.9       0.98          1      0.995      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      4.59G     0.6222     0.8407     0.5573     0.9546         27        640: 100% 2/2 [00:02<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.73it/s]\n",
      "                   all          7          7       0.98          1      0.995        0.9       0.98          1      0.995      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      4.59G      0.731      0.813     0.6462      1.011         17        640: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.76it/s]\n",
      "                   all          7          7       0.97          1      0.995      0.908       0.97          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      4.59G     0.6267     0.9001     0.5339     0.9224         21        640: 100% 2/2 [00:02<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.71it/s]\n",
      "                   all          7          7       0.97          1      0.995      0.908       0.97          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      4.59G     0.5669     0.7952     0.4615     0.9309         14        640: 100% 2/2 [00:02<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.77it/s]\n",
      "                   all          7          7      0.976          1      0.995      0.937      0.976          1      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      4.59G      0.632     0.8803     0.5789     0.9396         24        640: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.76it/s]\n",
      "                   all          7          7      0.976          1      0.995      0.937      0.976          1      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      4.59G     0.6992      0.958     0.6249     0.9993         16        640: 100% 2/2 [00:02<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.87it/s]\n",
      "                   all          7          7      0.975          1      0.995      0.873      0.975          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      4.59G     0.5894     0.8069     0.5226     0.9193         22        640: 100% 2/2 [00:02<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.82it/s]\n",
      "                   all          7          7      0.975          1      0.995      0.873      0.975          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      4.59G     0.6171     0.8092     0.4833     0.9367         26        640: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.78it/s]\n",
      "                   all          7          7      0.979          1      0.995      0.807      0.979          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      4.59G     0.6404     0.9405     0.4959     0.9627         29        640: 100% 2/2 [00:02<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.75it/s]\n",
      "                   all          7          7      0.979          1      0.995      0.807      0.979          1      0.995      0.898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      4.59G     0.7597     0.9603     0.6288     0.9705         20        640: 100% 2/2 [00:02<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.981          1      0.995      0.845      0.981          1      0.995      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      4.59G     0.6159      0.847     0.4302     0.9498         23        640: 100% 2/2 [00:02<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
      "                   all          7          7      0.981          1      0.995      0.845      0.981          1      0.995      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      4.59G     0.6044     0.7945       0.46     0.9001         27        640: 100% 2/2 [00:02<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.80it/s]\n",
      "                   all          7          7       0.96          1      0.995       0.84       0.96          1      0.995      0.898\n",
      "Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 10, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "60 epochs completed in 0.059 hours.\n",
      "Optimizer stripped from runs/segment/train2/weights/last.pt, 23.8MB\n",
      "Optimizer stripped from runs/segment/train2/weights/best.pt, 23.8MB\n",
      "\n",
      "Validating runs/segment/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.19 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11780374 parameters, 0 gradients, 42.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.59it/s]\n",
      "                   all          7          7      0.843      0.922      0.995      0.981      0.843      0.922      0.995      0.882\n",
      "           Arduino-uno          7          6          1      0.843      0.995      0.968          1      0.843      0.995      0.868\n",
      "                 Esp32          7          1      0.687          1      0.995      0.995      0.687          1      0.995      0.895\n",
      "Speed: 0.3ms pre-process, 8.7ms inference, 0.0ms loss, 1.9ms post-process per image\n",
      "Results saved to \u001b[1mruns/segment/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=segment mode=train model=yolov8s-seg.pt data={dataset.location}/data.yaml epochs=100 imgsz=640"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
